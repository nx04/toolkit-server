# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
    stdin{
    }
    jdbc {
      # 连接的数据库地址和数据库，指定编码格式，禁用SSL协议，设定自动重连
      jdbc_connection_string => "jdbc:mysql://192.168.91.146:50112/advertising?characterEncoding=UTF-8&useSSL=false&autoReconnect=true"
      # 用户名密码
      jdbc_user => "root"
      jdbc_password => "123456"
      # jar包的位置
      jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/mysql-connector-java-5.1.5-bin.jar"
      # mysql的Driver
      jdbc_driver_class => "com.mysql.jdbc.Driver"
      jdbc_default_timezone => "Asia/Shanghai"
      jdbc_paging_enabled => "true"
      jdbc_page_size => "100"
      #statement_filepath => "config-mysql/test.sql"
      #注意这个sql不能出现type，这是es的保留字段
      statement => "select id,title from cr_article where id>:sql_last_value order by id asc"
      schedule => "* * * * *"
      #将时间数据写入到文件中
      #record_last_run => true
      # 是否需要记录某个column 的值
      use_column_value => true
      # 如果 use_column_value 为真,需配置此参数. track 的数据库 column 名,该 column 必须是递增的. 一般是mysql主键
      tracking_column => "id"
      tracking_column_type => "numeric"
      #last_run_metadata_path => "/usr/share/logstash/config/logstash_metadata"
    }
}

output {
  elasticsearch {
    hosts => ["http://172.19.92.1:9200"]
    user => "elastic"
    password => "aa5626188"
    index => "test_abc"
    document_id => "%{id}"
  }
}